{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFd6k16IGIT9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/cumulative.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "BX3okFZCGT4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive_info = ['kepler_name', 'kepid', 'kepoi_name', 'koi_disposition', 'koi_pdisposition', 'rowid']\n",
        "data = data.drop(archive_info, axis=1)"
      ],
      "metadata": {
        "id": "3f7vOP_3H2rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_disposition = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
        "data = data.drop(project_disposition, axis=1)"
      ],
      "metadata": {
        "id": "gxjyISMeHnHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_crossing_events = ['koi_model_snr', 'koi_tce_plnt_num', 'koi_tce_delivname']\n",
        "data = data.drop(threshold_crossing_events, axis=1)"
      ],
      "metadata": {
        "id": "cxE0y6uhJpN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kic_parameters = ['ra', 'dec', 'koi_kepmag']\n",
        "data = data.drop(kic_parameters, axis=1)"
      ],
      "metadata": {
        "id": "fKh8x6RBLEFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transit_properties = ['koi_period_err1', 'koi_period_err2', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact_err1', 'koi_impact_err2', 'koi_duration_err1', \n",
        "                      'koi_duration_err2', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq_err1', 'koi_teq_err2', 'koi_insol_err1', \n",
        "                      'koi_insol_err2', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad_err1', 'koi_srad_err2']\n",
        "data = data.drop(transit_properties, axis=1)"
      ],
      "metadata": {
        "id": "eJzmq9ki693I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "XeEDCGRA1KS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "yZv3iee23Z7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "Xy_YEjhKw6wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['koi_period', 'koi_time0bk', 'koi_impact', 'koi_duration', 'koi_depth', 'koi_prad', 'koi_teq', 'koi_insol', 'koi_steff', 'koi_slogg', 'koi_srad']\n",
        "data_features = data[features]\n",
        "\n",
        "data_features.head()"
      ],
      "metadata": {
        "id": "onIWDg84Nq0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_target = data['koi_score']"
      ],
      "metadata": {
        "id": "xDIfvam-QxQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_PM0GUI6RItM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExoplanetDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, train=True):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(torch.from_numpy(data_features.values).float(), \n",
        "                                                            torch.from_numpy(data_target.values).float(), \n",
        "                                                            test_size=0.2, \n",
        "                                                            random_state=0)\n",
        "        \n",
        "        if train:\n",
        "            self.x_data, self.y_data = x_train, y_train\n",
        "        else:\n",
        "            self.x_data, self.y_data = x_test, y_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y_data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x_data[i], self.y_data[i]"
      ],
      "metadata": {
        "id": "5w8nGbmxRmbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(ExoplanetDataset(train=True), batch_size=12)\n",
        "test_loader = torch.utils.data.DataLoader(ExoplanetDataset(train=False), batch_size=12)"
      ],
      "metadata": {
        "id": "eQWaWbFBzk7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "PbOnecUPR9tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 11\n",
        "output_size = 1\n",
        "hid1_size = 20\n",
        "hid2_size = 10"
      ],
      "metadata": {
        "id": "TDCls_o3SC5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hid1_size)\n",
        "    self.fc2 = nn.Linear(hid1_size, hid2_size)\n",
        "    self.fc3 = nn.Linear(hid2_size, output_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = torch.sigmoid(self.fc1(x))\n",
        "    x = torch.sigmoid(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "Gz3krX2eSPGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()"
      ],
      "metadata": {
        "id": "yrnQCjmSSqxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.L1Loss(reduction='mean')"
      ],
      "metadata": {
        "id": "0RuAwSJ3Sv8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_data = []\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "fUJ0RVy0S28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    valid_loss = 0\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output_train = model(x)\n",
        "        loss = loss_fn(output_train.squeeze(1), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            output_test = model(x)\n",
        "            loss = loss_fn(output_test.squeeze(1), y)\n",
        "            valid_loss += loss.item()\n",
        "            valid_loss /= len(test_loader)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Training loss: {loss.item()} \\| Valid loss: {valid_loss}\")\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcPIT4qLS-iK",
        "outputId": "0e42acde-6346-4eba-df74-64bfdb658bbe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.18527726829051971 \\| Valid loss: 0.001392566091486623\n",
            "Training loss: 0.18398189544677734 \\| Valid loss: 0.0013870735553432945\n",
            "Training loss: 0.18216216564178467 \\| Valid loss: 0.0013688187397580512\n",
            "Training loss: 0.18602077662944794 \\| Valid loss: 0.0013977914381117173\n",
            "Training loss: 0.18485140800476074 \\| Valid loss: 0.0013892560240616322\n",
            "Training loss: 0.1849900484085083 \\| Valid loss: 0.0013903991405793644\n",
            "Training loss: 0.18614010512828827 \\| Valid loss: 0.0013986333558347866\n",
            "Training loss: 0.18308742344379425 \\| Valid loss: 0.0013757235661478397\n",
            "Training loss: 0.18315689265727997 \\| Valid loss: 0.001376241912670444\n",
            "Training loss: 0.1804952621459961 \\| Valid loss: 0.0013565849588303342\n"
          ]
        }
      ]
    }
  ]
}